{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OVMS Inference Template\n",
    "This file is meant to help you with building an inference application for any. \n",
    "It contains snippets that handle:\n",
    "* connecting to a image feed published RTSP stream\n",
    "* connecting to OVMS via gRPC\n",
    "* converting images to the proper format \n",
    "* running inference\n",
    "* displaying results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, io, time, imutils, datetime, os, traceback, grpc\n",
    "from imutils.video import VideoStream\n",
    "import opencv_jupyter_ui as jcv2\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import make_tensor_proto, make_ndarray\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "\n",
    "FPS = 15\n",
    "MODEL_NAME = \"\"\n",
    "RTSP_URL = \"rtsp://localhost:8554/server\"\n",
    "GRPC_URL = \"localhost:9000\"\n",
    "INPUT_LAYER_NAME = \"\"\n",
    "INPUT_LAYER_FORMAT = \"float32\"\n",
    "OUTPUT_LAYER_NAME = \"\"\n",
    "BATCH_SIZE = 1\n",
    "HEIGHT = 200\n",
    "WIDTH = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open gRPC channel and RTSP Feed\n",
    "The gRPC channel is used to talk to the OVMS service.\n",
    "The frames from your webcam are going to be published to an RTSP stream by the `video-capture` service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = grpc.insecure_channel(GRPC_URL)\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "print(\"* GRPC Channel succesfully opened\")\n",
    "\n",
    "\n",
    "try:\n",
    "    rtsp_stream = VideoStream(RTSP_URL).start()\n",
    "    print(\"* RTSP Stream succesfully opened\")\n",
    "except Exception as e:\n",
    "    print(\"* RTSP Stream is unavailable, please close any other notebooks that might be accessing the stream first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the input frame to the correct format\n",
    "This is highly dependent on the model you are going to use, but there are three steps you might need to take to convert your image\n",
    "1. Resize, you can see what size your image needs to be by checking the shape of the input layer in `<model_name>.mapping`\n",
    "2. Transpose and reshape the image to the correct format. You can check the model page on OMZ for more details\n",
    "3. Convert the image to the datatype your model accepts\n",
    "\n",
    "The following steps were taken to convert the image for the `face_detection` demo. Feel free to modify it to fit your purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img):\n",
    "    img = cv2.resize(img, (WIDTH, HEIGHT))\n",
    "    img = img.transpose(2,0,1).reshape(1,3,HEIGHT, WIDTH)\n",
    "    img = img.astype(INPUT_LAYER_FORMAT)\n",
    "    return img "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference \n",
    "This method connects to OVMS using gRPC, sends the (conveted) image and returns the output tensor in numpy format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_inference(img):\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = MODEL_NAME\n",
    "    request.inputs[INPUT_LAYER_NAME].CopyFrom(make_tensor_proto(img, shape=(img.shape)))\n",
    "    result = stub.Predict(request, 10.0)\n",
    "    return make_ndarray(result.outputs[OUTPUT_LAYER_NAME])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program Loop\n",
    "\n",
    "This loop gets new frames from the RTSP Stream, converts images, sends them to OVMS for inference, and displays the result inside an embedded video-box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try: \n",
    "        frame = rtsp_stream.read()\n",
    "        try: \n",
    "            if frame is not None:\n",
    "                prepared = load_image(frame)\n",
    "                output = do_inference(prepared)\n",
    "                \n",
    "                ## Here you'll probably do something to the output from the inference server\n",
    "                ## And here you'll probably draw bounding boxes on top of the frame from the camera\n",
    "\n",
    "                jcv2.imshow(\"Prediction Output\", frame) # This displays the image inside an embedded video-box\n",
    "            else: \n",
    "                continue \n",
    "                \n",
    "            time.sleep(FPS)\n",
    "        except Exception as e:\n",
    "            print(\"error while running inference\", e)\n",
    "            print(traceback.format_exc())\n",
    "          \n",
    "    except Exception as e:\n",
    "        print(\"error while grabbing RTSP stream\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
